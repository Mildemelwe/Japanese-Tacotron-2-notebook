{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Japanese Tacotron 2 training (redone).ipynb","provenance":[],"authorship_tag":"ABX9TyPX/LgrNoGPzW+Eg/1Cxu3L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"9D8N7XjI-YUm"},"outputs":[],"source":["#@markdown # Check GPU type\n","#@markdown ### Factory reset runtime if you don't have the desired GPU.\n","\n","#@markdown ---\n","\n","#@markdown ## It is recommended to not use the K80\n","\n","!nvidia-smi -L\n","#@markdown All GPUs work properly, but vary in speed. K80 and P4 are not recommended.\n","\n","#@markdown ---"]},{"cell_type":"code","source":["#@markdown # Anti-Disconnect for Google Colab\n","#@markdown ## Run this to stop it from disconnecting automatically (will disconnect after 6 - 12 hours, though.)\n","\n","import IPython\n","js_code = '''\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}\n","setInterval(ClickConnect,60000)\n","'''\n","display(IPython.display.Javascript(js_code))"],"metadata":{"cellView":"form","id":"4YQW29QA-dYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ## Mount your Google Drive\n","\n","#Google Drive Authentication Token\n","from google.colab import drive\n","drive.mount('drive')"],"metadata":{"cellView":"form","id":"i2gaIgCQ-jaD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown # Download pretrained model and install tacotron 2\n","\n","#make wavs folder\n","!mkdir '/content/wavs'\n","\n","#get haruqa japanese pretrained model\n","!gdown https://drive.google.com/uc?id=1j986QrB1C-tY4GLq806xMBfMWVO3YKY8\n","\n","#download tacotron 2\n","!git clone -q https://github.com/NVIDIA/tacotron2\n","!pip install unidecode\n","!pip install tensorflow==1.15"],"metadata":{"id":"zPHDhXfz-tvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown # Optional: Unzip file to unpack wavs\n","#@markdown ### If you have a lot of wav files, then zip them all into one file locally on your system, then upload it and copy the path. Otherwise, you may just upload your wavs to /wavs.\n","#@markdown ---\n","\n","zip_file_path = \"/content/wavs.zip\" #@param {type:\"string\"}\n","!unzip $zip_file_path -d '/content/wavs'"],"metadata":{"cellView":"form","id":"MnvOEqSM-g7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown This is for your training configuration (hparams.py)\n","\n","%%writefile /content/tacotron2/hparams.py\n","import tensorflow as tf\n","from text import symbols\n","\n","transcription='/content/tacotron2/filelists/transcription.txt'#@param {type:'string'}\n","batchsize=8#@param {type: 'integer'}\n","\n","def create_hparams(hparams_string=None, verbose=False):\n","    \"\"\"Create model hyperparameters. Parse nondefault from given string.\"\"\"\n","\n","    hparams = tf.contrib.training.HParams(\n","        ################################\n","        # Experiment Parameters        #\n","        ################################\n","        epochs=5000,\n","        iters_per_checkpoint=100,\n","        seed=1234,\n","        dynamic_loss_scaling=True,\n","        fp16_run=False,\n","        distributed_run=False,\n","        dist_backend=\"nccl\",\n","        dist_url=\"tcp://localhost:54321\",\n","        cudnn_enabled=True,\n","        cudnn_benchmark=False,\n","        ignore_layers=['embedding.weight'],\n","\n","        ################################\n","        # Data Parameters             #\n","        ################################\n","        load_mel_from_disk=False,\n","        training_files=transcription,\n","        validation_files=transcription,\n","        text_cleaners=['convert_to_ascii'],\n","\n","        ################################\n","        # Audio Parameters             #\n","        ################################\n","        max_wav_value=32768.0,\n","        sampling_rate=22050,\n","        filter_length=1024,\n","        hop_length=256,\n","        win_length=1024,\n","        n_mel_channels=80,\n","        mel_fmin=0.0,\n","        mel_fmax=8000.0,\n","\n","        ################################\n","        # Model Parameters             #\n","        ################################\n","        n_symbols=len(symbols),\n","        symbols_embedding_dim=512,\n","\n","        # Encoder parameters\n","        encoder_kernel_size=5,\n","        encoder_n_convolutions=3,\n","        encoder_embedding_dim=512,\n","\n","        # Decoder parameters\n","        n_frames_per_step=1,  # currently only 1 is supported\n","        decoder_rnn_dim=1024,\n","        prenet_dim=256,\n","        max_decoder_steps=1000,\n","        gate_threshold=0.5,\n","        p_attention_dropout=0.1,\n","        p_decoder_dropout=0.1,\n","\n","        # Attention parameters\n","        attention_rnn_dim=1024,\n","        attention_dim=128,\n","\n","        # Location Layer parameters\n","        attention_location_n_filters=32,\n","        attention_location_kernel_size=31,\n","\n","        # Mel-post processing network parameters\n","        postnet_embedding_dim=512,\n","        postnet_kernel_size=5,\n","        postnet_n_convolutions=5,\n","\n","        ################################\n","        # Optimization Hyperparameters #\n","        ################################\n","        use_saved_learning_rate=False,\n","        learning_rate=1e-3,\n","        weight_decay=1e-6,\n","        grad_clip_thresh=1.0,\n","        batch_size=batchsize, #if you have the T4, set this to 14 or less\n","        mask_padding=True  # set model's padded outputs to padded values\n","    )\n","\n","    if hparams_string:\n","        tf.logging.info('Parsing command line hparams: %s', hparams_string)\n","        hparams.parse(hparams_string)\n","\n","    if verbose:\n","        tf.logging.info('Final parsed hparams: %s', hparams.values())\n","\n","    return hparams"],"metadata":{"id":"aTRLsjM--7Lz","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown # Launch TensorBoard\n","\n","!rm -rf '/content/logs'\n","!mkdir '/content/logs'\n","import tensorflow as tf\n","import datetime\n","%reload_ext tensorboard\n","%tensorboard --logdir '/content/logs'"],"metadata":{"id":"V0LAJDZMDWCI","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown # Begin training\n","\n","#outputdirectory = \"/content/drive/MyDrive/jsut_loanwords128\" #@param{type:'string'}\n","\n","!python /content/tacotron2/train.py \\\n","--log_directory='/content/logs' -c '/content/FlatBaseModel_frontVoiceIsAkitoTenohira_20210418.pt' --warm_start \\\n","--output_directory=\"/content/drive/MyDrive/jsut_loanwords128\" #@param{type:'string'}"],"metadata":{"id":"E4ygY6sEDDKZ"},"execution_count":null,"outputs":[]}]}